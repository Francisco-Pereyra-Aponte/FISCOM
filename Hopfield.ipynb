{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estudio de redes recurrentes: Hopfield "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from numba import njit  # Just-in-time compilation for faster execution opcional (si no se tiene comentar la linea y decoradores @njit)\n",
    "\n",
    "# path de los archivos\n",
    "path_ptt = \"./patterns/\"\n",
    "path_im = \"./images/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patrones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Print_Pattern(patterns, save = False):\n",
    "    \"\"\"\n",
    "        Displays and optionally saves a list of patterns as images.\n",
    "\n",
    "        Parameters:\n",
    "        patterns (list of numpy arrays): A list of 1D numpy arrays representing the patterns to be displayed.\n",
    "        save (bool, optional): If True, saves the images to the specified path. Default is False.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "\n",
    "        Notes:\n",
    "        - Each pattern in the list is reshaped into a square 2D array based on the length of the first pattern.\n",
    "        - The images are displayed using matplotlib's imshow function.\n",
    "        - If save is True, the images are saved to the path specified by the global variable 'path_ptt' with filenames 'Pattern_i.png', where 'i' is the pattern index.\n",
    "    \"\"\"\n",
    "    i=0\n",
    "    D = int(np.sqrt(len(patterns[0])))\n",
    "    for p in patterns:\n",
    "        p = p.reshape(D,D)\n",
    "        plt.imshow(p)\n",
    "        plt.title(f\"Patrón {i}\")\n",
    "        if save:\n",
    "            plt.savefig(os.path.join(path_ptt, f\"Pattern_{i}.png\"))\n",
    "        i+=1\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "def Delete_Patterns(P, n): \n",
    "    \"\"\"\n",
    "        Deletes the n-th pattern from the list of patterns P.\n",
    "    \"\"\"\n",
    "    return np.delete(P,n,0)\n",
    "\n",
    "def Import_Nist(N, delete=[], D=18):\n",
    "    \"\"\"\n",
    "        Imports and processes MNIST data.\n",
    "        Parameters:\n",
    "        N (int, list, \"all\"): Specifies which patterns to import. If an integer, the first N patterns are imported. \n",
    "                               If a list, the patterns at the specified indices are imported. \n",
    "                               If 'all', the first 1000 patterns are imported.\n",
    "        delete (list, optional): List of indices of patterns to delete after import. Defaults to an empty list.\n",
    "        D (int, optional): Dimension of the square submatrix to extract from the center of each pattern. Defaults to 18.\n",
    "        Returns:\n",
    "        numpy.ndarray: Array of processed patterns with values -1 and 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    data = np.loadtxt(os.path.join(path_ptt, 'mnist_train.csv'), delimiter=',') \n",
    "    \n",
    "    if type(N) == int:\n",
    "        ptts = data[:N,1:]\n",
    "    elif type(N) == list:\n",
    "        ptts = data[N,1:]\n",
    "    elif N == 'all':\n",
    "        ptts = data[:1000,1:]\n",
    "\n",
    "    Patts = []\n",
    "    for i in range(len(ptts)):\n",
    "        aux = np.where(ptts[i] > 0, 1, -1)\n",
    "        aux = aux.reshape(28,28)\n",
    "        aux = aux[14-D//2:14+D//2,14-D//2:14+D//2]\n",
    "        aux = aux.reshape(D**2)\n",
    "        Patts.append(aux)\n",
    "\n",
    "\n",
    "    Patts = np.array(Patts)\n",
    "    delete = np.sort(delete)[::-1] #ordenar de mayor a menor delete\n",
    "    for i in delete:\n",
    "        Patts = Delete_Patterns(Patts, i)\n",
    "    return Patts\n",
    "\n",
    "@njit\n",
    "def crear_patrones(p, N):\n",
    "    \"\"\"\n",
    "    Creates a matrix of patterns for a Hopfield network.\n",
    "\n",
    "    Parameters:\n",
    "    p (int): The number of patterns to create.\n",
    "    N (int): The number of neurons.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: A matrix of shape (p, N) where each element is either 1 or -1.\n",
    "    \"\"\"\n",
    "    random_matrix = np.random.uniform(0, 1, (p, N))\n",
    "    return np.where(random_matrix > 0.5, 1, -1).astype(np.float64)\n",
    "\n",
    "\n",
    "def similarity(Patts): \n",
    "    \"\"\"\n",
    "    Calculate the similarity matrix and mean patterns.\n",
    "    This function computes a symmetric similarity matrix for a given list of patterns.\n",
    "    Additionally, it returns the mean of each pattern.\n",
    "    Parameters:\n",
    "    Patts (list of np.ndarray): A list of patterns where each pattern is represented as a numpy array.\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - float: The sum of the similarity matrix elements minus the number of patterns.\n",
    "        - list: A list of mean values for each pattern.\n",
    "    \"\"\"\n",
    "    M = np.zeros((len(Patts), len(Patts)))\n",
    "\n",
    "    for i in range(len(Patts)):\n",
    "        for j in range(i, len(Patts)):\n",
    "            M[i,j] = np.abs(np.dot(Patts[i], Patts[j])/(np.linalg.norm(Patts[i])*np.linalg.norm(Patts[j])))\n",
    "            M[j,i] = M[i,j]\n",
    "    \n",
    "    med_patts = [np.mean(p) for p in Patts]\n",
    "    \n",
    "    return np.sum(M) - len(Patts), med_patts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones auxiliares:\n",
    "Energía - Distintas formas de W - Función de actualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def Energía(W, State, theta):\n",
    "    return -0.5 * np.dot(State, np.dot(W, State)) + np.dot(theta, State)\n",
    "\n",
    "@njit\n",
    "def W_matrix_Hebb(patrones):\n",
    "    \"\"\"\n",
    "    Computes the weight matrix using the Hebbian learning rule for a given set of patterns.\n",
    "\n",
    "    Parameters:\n",
    "    patrones (numpy.ndarray): A 2D array of shape (P, N) where P is the number of patterns \n",
    "                            and N is the number of neurons in each pattern.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - W (numpy.ndarray): The weight matrix of shape (N, N) with the weights between neurons.\n",
    "        - theta (numpy.ndarray): A zero vector of the same length as the number of neurons representing the threshold for each neuron.\n",
    "    \"\"\"\n",
    "\n",
    "    N = patrones.shape[1]\n",
    "    W = np.zeros((N,N)).astype(np.float64)\n",
    "\n",
    "    for i in range(len(patrones)):\n",
    "        W += np.outer(patrones[i], patrones[i])\n",
    "\n",
    "    W /= N\n",
    "    np.fill_diagonal(W, 0)\n",
    "\n",
    "    theta = np.zeros(N).astype(np.float64)\n",
    "\n",
    "    return W , theta\n",
    "\n",
    "@njit\n",
    "def W_matrix_Storkey(patrones):\n",
    "    \"\"\"\n",
    "    Computes the weight matrix using the Storkey learning rule for a set of patterns.\n",
    "    Parameters:\n",
    "    patrones (numpy.ndarray): A 2D array of shape (P, N) where P is the number of patterns \n",
    "                            and N is the number of neurons in each pattern.\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - W (numpy.ndarray): The weight matrix of shape (N, N) with the weights between neurons.\n",
    "        - theta (numpy.ndarray): A zero vector of the same length as the number of neurons representing the threshold for each neuron.\n",
    "    \"\"\"\n",
    "\n",
    "    P, N = patrones.shape\n",
    "    W = np.zeros((N, N), dtype=np.float64)\n",
    "\n",
    "    for mu in range(P):  # Para cada patrón\n",
    "        pattern = patrones[mu]\n",
    "\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                if i != j:\n",
    "                    h_j = np.sum(W[j, :] * pattern)  # Campo local en j\n",
    "                    h_i = np.sum(W[i, :] * pattern)  # Campo local en i\n",
    "                    W[i, j] += (pattern[i] * pattern[j] - pattern[i] * h_j - pattern[j] * h_i) / N\n",
    "\n",
    "    \n",
    "    np.fill_diagonal(W, 0)  # Aseguramos que los elementos diagonales son 0\n",
    "    theta = np.zeros(N, dtype=np.float64)\n",
    "    \n",
    "    return W, theta\n",
    "\n",
    "@njit\n",
    "def W_matrix_Hebb_cm(patrones):\n",
    "    \"\"\"\n",
    "    Computes the weight matrix using the Hebbian learning rule for a given set of patterns. \n",
    "    This version uses the  Mean-field of the patterns to calculate the threshold.\n",
    "\n",
    "    Parameters:\n",
    "    patrones (numpy.ndarray): A 2D array of shape (P, N) where P is the number of patterns \n",
    "                            and N is the number of neurons in each pattern.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - W (numpy.ndarray): The weight matrix of shape (N, N) with the weights between neurons.\n",
    "        - theta (numpy.ndarray): A vector of the same length as the number of neurons representing the threshold for each neuron.\n",
    "    \"\"\"\n",
    "    N = patrones.shape[1] # cantidad de neuronas\n",
    "    W = np.zeros((N,N)).astype(np.float64)\n",
    "\n",
    "    for i in range(len(patrones)):\n",
    "        W += np.outer(patrones[i], patrones[i])\n",
    "\n",
    "    W /= N\n",
    "    np.fill_diagonal(W, 0)\n",
    "\n",
    "    theta = 0\n",
    "    # sumo sobre patrones y neuronas\n",
    "    for i in range(len(patrones)):\n",
    "        for j in range(len(patrones[i])):\n",
    "            theta += patrones[i][j]\n",
    "    \n",
    "    theta /= (N*len(patrones))\n",
    "    theta = np.ones(N)*theta\n",
    "\n",
    "    return W , theta\n",
    "\n",
    "@njit\n",
    "def W_matrix_hebb_matto(patrones):\n",
    "    \"\"\"\n",
    "    Computes the weight matrix using a modification of the Hebbian learning rule proposed by German Matto for a given set of patterns.\n",
    "    This version tries to fix the problem that the patterns do not have zero mean. \n",
    "\n",
    "    Parameters:\n",
    "    patrones (numpy.ndarray): A 2D array of shape (P, N) where P is the number of patterns \n",
    "                            and N is the number of neurons in each pattern.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - W (numpy.ndarray): The weight matrix of shape (N, N) with the weights between neurons.\n",
    "        - theta (numpy.ndarray): A zero vector of the same length as the number of neurons representing the threshold for each neuron.\n",
    "    \"\"\"\n",
    "    N = patrones.shape[1]\n",
    "    W = np.zeros((N,N)).astype(np.float64)\n",
    "\n",
    "    med_patts = [np.mean(p) for p in patrones]\n",
    "    med_patts = np.array(med_patts).astype(np.float64)\n",
    "\n",
    "    for i in range(len(patrones)):\n",
    "        W += np.outer(patrones[i]-med_patts[i], patrones[i]-med_patts[i])\n",
    "\n",
    "    W /= N\n",
    "    np.fill_diagonal(W, 0)\n",
    "\n",
    "    theta = np.zeros(N).astype(np.float64)\n",
    "\n",
    "    return W , theta\n",
    "\n",
    "@njit\n",
    "def W_matrix_hebb_theta(patrones):\n",
    "    \"\"\"\n",
    "    Computes the weight matrix (W) and threshold vector (theta) for a Hopfield network using the Hebbian learning rule.\n",
    "    This version calculates the threshold vector as the average of each neuron's activity over all patterns.\n",
    "\n",
    "    Parameters:\n",
    "    patrones (numpy.ndarray): A 2D array where each row represents a pattern. The shape of the array is (P, N),\n",
    "                              where P is the number of patterns and N is the number of neurons.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - W (numpy.ndarray): The weight matrix of shape (N, N) with zero diagonal.\n",
    "        - theta (numpy.ndarray): The threshold vector of shape (N,).\n",
    "    \"\"\"\n",
    "    \n",
    "    N = patrones.shape[1]\n",
    "    W = np.zeros((N,N)).astype(np.float64)\n",
    "\n",
    "    for i in range(len(patrones)):\n",
    "        W += np.outer(patrones[i], patrones[i])\n",
    "\n",
    "    W /= N\n",
    "    np.fill_diagonal(W, 0)\n",
    "\n",
    "    theta = np.zeros(N).astype(np.float64)\n",
    "    for i in range(len(patrones)):\n",
    "        theta -= patrones[i]\n",
    "        theta = theta / len(patrones)\n",
    "\n",
    "    return W , theta\n",
    "\n",
    "@njit\n",
    "def Update_secuential(W, s, theta):\n",
    "    \"\"\"\n",
    "    Perform a sequential update of the state vector `s` using the weight matrix `W` and threshold vector `theta`.\n",
    "\n",
    "    Parameters:\n",
    "    W (numpy.ndarray): The weight matrix.\n",
    "    s (numpy.ndarray): The initial state vector.\n",
    "    theta (numpy.ndarray): The threshold vector.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - s_new (numpy.ndarray): The updated state vector.\n",
    "        - E (list): A list of energy values after each update.\n",
    "    \"\"\"\n",
    "    E = []\n",
    "    s_new = np.copy(s)\n",
    "    index = np.arange(len(s))\n",
    "\n",
    "    E.append(Energía(W, s_new, theta))\n",
    "\n",
    "    np.random.shuffle(index)\n",
    "    for j in index:\n",
    "        if (np.dot(W[j], s_new) - theta[j] <0):\n",
    "            s_new[j] = -1\n",
    "        if (np.dot(W[j], s_new) - theta[j] >0):\n",
    "            s_new[j] = 1\n",
    "        else:   s_new[j] = s_new[j] # linea que no hace falta\n",
    "        # if np.dot(W[j], s_new) - theta[j] == 0: s_new[j] = s_new[j]\n",
    "        # else: s_new[i] = np.sign(np.dot(W[i], s_new) - theta)\n",
    "        E.append(Energía(W, s_new, theta))\n",
    "\n",
    "    return s_new, E\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clase principal de Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hopfield_NN:\n",
    "    def __init__(self, N, type):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        N (int): The number of neurons in the network.\n",
    "        type (str): The type of the network (e.g., 'binary', 'continuous').\n",
    "\n",
    "        Attributes:\n",
    "        N (int): The number of neurons in the network.\n",
    "        State (np.ndarray): The state of each neuron, initialized randomly to -1 or 1.\n",
    "        theta (np.ndarray): The threshold for each neuron, initialized to zeros.\n",
    "        W (np.ndarray): The weight matrix of the network, initialized to zeros.\n",
    "        type (str): The type Computes the weight - 'hebb', 'storkey', 'hebb_cm', 'hebb_matto', 'hebb_theta'\n",
    "        \"\"\"\n",
    "        self.N = N\n",
    "        self.State = np.random.choice([-1,1], N).astype(np.float64)\n",
    "        self.theta = np.zeros(N).astype(np.float64)\n",
    "        self.W = np.zeros((N,N)).astype(np.float64)\n",
    "        self.type = type\n",
    "\n",
    "    \n",
    "    def Save_pattern(self, patrones):\n",
    "        \"\"\"\n",
    "        Save the pattern into the weight matrix and threshold vector based on the specified type.\n",
    "\n",
    "        Parameters:\n",
    "        patrones (list or array-like): The patterns to be saved.\n",
    "        \"\"\"\n",
    "        if self.type == 'hebb': self.W, self.theta = W_matrix_Hebb(patrones)\n",
    "        if self.type == 'storkey': self.W, self.theta = W_matrix_Storkey(patrones)\n",
    "        if self.type == 'hebb_cm': self.W, self.theta = W_matrix_Hebb_cm(patrones)\n",
    "        if self.type == 'hebb_matto': self.W, self.theta = W_matrix_hebb_matto(patrones)\n",
    "        if self.type == 'hebb_theta': self.W, self.theta = W_matrix_hebb_theta(patrones)\n",
    "        \n",
    "    \n",
    "    def Update_epoch(self, print_state = False):\n",
    "        \"\"\"\n",
    "        Updates the state of the network for one epoch using sequential update rule.\n",
    "\n",
    "        Parameters:\n",
    "        print_state (bool): If True, the function will print the state and energy plot. Default is False.\n",
    "\n",
    "        Returns:\n",
    "        E (list): The energy of the network at each iteration within the epoch\n",
    "        \"\"\"\n",
    "        self.State , E = Update_secuential(self.W, self.State, self.theta)\n",
    "        if print_state:\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "            plt.sca(axes[0])\n",
    "            plt.imshow(self.State.reshape(int(np.sqrt(self.N)), int(np.sqrt(self.N))))\n",
    "            plt.sca(axes[1])\n",
    "            plt.plot(E)\n",
    "            plt.show()\n",
    "        return E\n",
    "    \n",
    "    \n",
    "    def Energy(self):\n",
    "        \"\"\"\n",
    "        Returns the energy of the network.\n",
    "        \"\"\"\n",
    "\n",
    "        return Energía(self.W, self.State, self.theta)\n",
    "    \n",
    "    def Print(self):\n",
    "        \"\"\"\n",
    "        Prints the state of the network as an image.\n",
    "        \"\"\"\n",
    "\n",
    "        plt.imshow(self.State.reshape(int(np.sqrt(self.N)),int(np.sqrt(self.N))))\n",
    "\n",
    "    def Noise(self, p):\n",
    "        \"\"\"\n",
    "        Adds noise to the state of the network.\n",
    "\n",
    "        Parameters:\n",
    "        p (float): The percentage of neurons to change.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "\n",
    "        #cambio p porciento de los valores\n",
    "        index = np.random.choice(np.arange(self.N), int(p*self.N))\n",
    "        self.State[index] = -self.State[index]\n",
    "        \n",
    "    def Set_state(self, state):\n",
    "        \"\"\"\n",
    "        Sets the state of the network to the specified state.\n",
    "\n",
    "        Parameters:\n",
    "        state (np.ndarray): The state to set the network to.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.State = state.astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estudios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolucion de E\n",
    "Dada una red de 32*32 se estudia la evolucion de la energia en funcion de las iteraciones de una epoca. Se guardo un patron generado aleatorio y se parte de otro patron aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lado = 32\n",
    "NN = Hopfield_NN(lado**2, 'hebb')\n",
    "\n",
    "fig , ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "plt.sca(ax[0])\n",
    "NN.Print()\n",
    "plt.title(\"Estado inicial\")\n",
    "\n",
    "Patts = crear_patrones(1, lado**2)\n",
    "plt.sca(ax[1])\n",
    "Print_Pattern(Patts)\n",
    "# plt.savefig(\"Pa.png\")\n",
    "\n",
    "NN.Save_pattern(Patts)\n",
    "E = NN.Update_epoch(print_state = True)\n",
    "\n",
    "dd = np.abs(np.array(NN.State) - np.array(Patts))\n",
    "print(np.sum(dd/2))\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.plot(E)\n",
    "plt.xlabel(\"Neurona\", fontsize=15)\n",
    "plt.ylabel(\"Energía\", fontsize=15)\n",
    "plt.yticks([0,-250, -500], fontsize=15)\n",
    "plt.xticks([0,512, 1024],fontsize=15)\n",
    "# plt.savefig(os.path.join(path_im, \"Energia.png\"), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capacidad\n",
    "Se estudia la capacidad de la red. Observando la cantidad de iteraciones para converger y el numero de errores en la recuperación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = np.array([500]); N = np.sqrt(N).astype(int) # cantidad de neuronas\n",
    "alpha = np.array([0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20]) # P/N\n",
    "p_noise = 0.20 # porcentaje de ruido\n",
    "\n",
    "for n in N:  # itero sobre tamaño de la red\n",
    "    Iteraciones = [] # n de it vs alpna\n",
    "    Diferencia = [] # diferencia entre el patron y el estado final\n",
    "\n",
    "    for a in alpha: # itero sobre cantidad de patrones\n",
    "\n",
    "        print(f\"N = {n**2}, p_noise = {p_noise}, alpha = {a}, {int(n**2*a)} patrones\")\n",
    "        Patts = crear_patrones(int(a*n**2), n**2)\n",
    "        NN = Hopfield_NN(n**2, 'hebb')\n",
    "        NN.Save_pattern(Patts)\n",
    "        n_it = [] # cantidad de iteraciones\n",
    "        n_dif = [] # diferencia entre el patron y el estado final\n",
    "\n",
    "        for i in range(len(Patts)): # itero sobre los patrones\n",
    "            NN.Set_state(Patts[i])\n",
    "            NN.Noise(p_noise)\n",
    "            \n",
    "            it = 0\n",
    "            while 1:\n",
    "                it += 1\n",
    "                E = NN.Update_epoch(print_state=0)\n",
    "                if E[0] == E[-1]:\n",
    "                    dd = np.sum(np.abs(np.array(NN.State) - np.array(Patts[i]))/2)\n",
    "                    if dd >  (n**2)/2 : n_dif.append(n**2-dd) # si la diferencia es mayor a la mitad de la red, tomo el complemento \n",
    "                    else: n_dif.append(dd)\n",
    "                    n_it.append(it-1)\n",
    "                    break\n",
    "                if it > 100: \n",
    "                    print(\"No converge\")\n",
    "\n",
    "                    dd = np.sum(np.abs(np.array(NN.State) - np.array(Patts[i]))/2)\n",
    "                    if dd >  (n**2)/2 : n_dif.append(n**2-dd) # si la diferencia es mayor a la mitad de la red, tomo el complemento\n",
    "                    else: n_dif.append(dd)\n",
    "                    n_it.append(it-1)\n",
    "                    break\n",
    "        \n",
    "        Iteraciones.append(np.mean(n_it))\n",
    "        Diferencia.append(np.mean(n_dif))\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "plt.sca(axes[0])\n",
    "plt.plot(alpha, Iteraciones, '-o')\n",
    "plt.xlabel(r'$\\alpha$', fontsize=15)\n",
    "plt.ylabel(\"Épocas\", fontsize=15)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "plt.vlines(0.14, np.min(Iteraciones), np.max(Iteraciones), color='red', linestyle='--', label=r\"$\\alpha_c = 0.14$\")\n",
    "plt.legend(fontsize=15, loc='lower right')\n",
    "\n",
    "plt.sca(axes[1])\n",
    "plt.plot(alpha, 100*np.array(Diferencia)/n**2, '-o')\n",
    "plt.vlines(0.14, np.min(100*np.array(Diferencia)/n**2), np.max(100*np.array(Diferencia)/n**2), color='red', linestyle='--', label=r\"$\\alpha_c = 0.14$\")\n",
    "plt.legend(fontsize=15, loc='lower right')\n",
    "plt.xlabel(r\"$\\alpha$\", fontsize=15)\n",
    "plt.ylabel(\"Diferencia[%]\", fontsize=15)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=13)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo Práctico con patrones M_nist\n",
    "para redes de 18*18, con regla de Hebb o variantes, los patrones utilizados minimizando la media y similaridad fueron: [0,1,5,12,20,25,52,85]\n",
    "para redes de 18*18, con regla de Storkey, los patrones utilizados fueron: [0,1,12,20,25,52,2,3,4,6,7,8,9,13,15,16,58,60,27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Patts = Import_Nist([0,1,12,20,25,52,2,3,4,6,7,8,9,13,15,16,58,60,27], D=18)#; Print_Pattern(Patts)\n",
    "NN = Hopfield_NN(18**2, 'storkey')\n",
    "NN.Save_pattern(Patts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIF = []\n",
    "IT = []\n",
    "for i in range(len(Patts)):\n",
    "    NN.Set_state(Patts[i])\n",
    "    # figura de 1x2 con el patron y noiseado\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    plt.sca(axes[0])\n",
    "    NN.Print()\n",
    "    plt.title(f\"Patrón {i}\")\n",
    "    plt.sca(axes[1])\n",
    "    NN.Noise(0.20)\n",
    "    NN.Print()\n",
    "    plt.title(f\"Patrón {i} con ruido\")\n",
    "    plt.show()\n",
    "\n",
    "    it = 0\n",
    "    while 1:\n",
    "        it += 1\n",
    "        E = NN.Update_epoch(print_state = False)\n",
    "        if E[0] == E[-1]:\n",
    "            break\n",
    "        if it > 100:\n",
    "            print(\"No converge\")\n",
    "            break\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    plt.sca(axes[0])\n",
    "    NN.Print()\n",
    "    plt.title(f\"Patrón {i} final, {it} iteraciones\")\n",
    "    IT.append(it)\n",
    "    plt.sca(axes[1])\n",
    "    plt.plot(E)\n",
    "    diff = np.sum(np.abs(np.array(NN.State) - np.array(Patts[i]))/2)\n",
    "    plt.title(f\"Diferencia = {diff}\")\n",
    "    DIF.append(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
